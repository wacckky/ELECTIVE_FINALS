# -*- coding: utf-8 -*-
"""FINAL ELECTIVES.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1klgaIXNCQHFfRlZc8zwPArQCP4r4L6O0

# **FINAL PROJECT**

## **Load Data**
"""

from google.colab import files
uploaded = files.upload()

import pandas as pd

# Load the uploaded file
df = pd.read_csv("MAINDATA (1).csv", encoding="ISO-8859-1")
df.head()

from google.colab import files

# Upload CSV file manually
uploaded = files.upload()

import pandas as pd

# Load the uploaded file (change name if needed)
team_def = pd.read_csv("Merged_Team_Defense.csv")

# Preview
team_def.head()



"""## **Processing Data**"""

# Drop duplicate rows
df = df.drop_duplicates()

# Clean text columns
df['Player'] = df['Player'].str.strip().str.title()
df['Tm'] = df['Tm'].str.strip().str.upper()
df['Opp'] = df['Opp'].str.strip().str.upper()
df['Pos'] = df['Pos'].str.strip().str.upper()

# Convert relevant columns to numeric
cols_to_numeric = ['MP', 'PTS', 'TRB', 'AST', 'TOV']
for col in cols_to_numeric:
    df[col] = pd.to_numeric(df[col], errors='coerce')

# Fill missing numeric values with column means
df.fillna(df.mean(numeric_only=True), inplace=True)

# Create a new feature only if required columns are present
if {'PTS', 'TRB', 'AST', 'TOV'}.issubset(df.columns):
    df['EFFICIENCY'] = df['PTS'] + df['TRB'] + df['AST'] - df['TOV']

# Check for remaining missing values
print("Missing values per column:\n", df.isnull().sum())

# Check data types and summary
print(df.info())
print(df.describe())

"""## **EDA**"""

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# -------------------------------------------
# ‚úÖ Convert all columns to numeric safely
numeric_df = df.apply(pd.to_numeric, errors='coerce')

# ‚úÖ Drop columns that are fully NaN (non-numeric originally)
numeric_df = numeric_df.dropna(axis=1, how='all')

# -------------------------------------------
# üìä Heatmap of correlations (ONLY numeric columns)
plt.figure(figsize=(12, 8))
sns.heatmap(numeric_df.corr(), annot=True, cmap='coolwarm')
plt.title("Feature Correlation Heatmap")
plt.show()

# -------------------------------------------
# üìà Histogram of Points
plt.figure(figsize=(8, 6))
sns.histplot(numeric_df['PTS'], bins=20, kde=True)
plt.title("Distribution of Points")
plt.xlabel("Points")
plt.ylabel("Frequency")
plt.show()

# -------------------------------------------
# üîç Scatter plot: Minutes Played vs Points
plt.figure(figsize=(8, 6))
sns.scatterplot(x='MP', y='PTS', data=numeric_df)
plt.title("Minutes Played vs Points")
plt.xlabel("Minutes Played")
plt.ylabel("Points")
plt.show()

"""## **MODEL BUILDING**"""

## **MODEL BUILDING**from sklearn.model_selection import train_test_split
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor
from sklearn.multioutput import MultiOutputRegressor

# Define target variables
y = numeric_df[['PTS', 'TRB', 'AST']]

# Define features by dropping target columns
X = numeric_df.drop(['PTS', 'TRB', 'AST'], axis=1)

"""## **MODEL BUILDING**"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Wrap XGBoost in MultiOutputRegressor for multi-target regression
xgb_model = MultiOutputRegressor(XGBRegressor(random_state=42, n_estimators=100))
xgb_model.fit(X_train, y_train)

xgb_pred = xgb_model.predict(X_test)

# Evaluation for XGBoost
print("üîπ XGBoost Evaluation:")
for i, target in enumerate(['PTS', 'TRB', 'AST']):
    mse = mean_squared_error(y_test.iloc[:, i], xgb_pred[:, i])
    r2 = r2_score(y_test.iloc[:, i], xgb_pred[:, i])
    print(f"{target} - RMSE: {mse**0.5:.2f}, R¬≤: {r2:.2f}")

for i, target in enumerate(['PTS', 'TRB', 'AST']):
    plt.figure(figsize=(6, 4))
    plt.scatter(y_test.iloc[:, i], xgb_pred[:, i], alpha=0.6)
    plt.plot([y_test.iloc[:, i].min(), y_test.iloc[:, i].max()],
             [y_test.iloc[:, i].min(), y_test.iloc[:, i].max()], 'r--')
    plt.xlabel(f"Actual {target}")
    plt.ylabel(f"Predicted {target}")
    plt.title(f"[XGBoost] Actual vs Predicted - {target}")
    plt.show()

rf_model = RandomForestRegressor(random_state=42)
rf_model.fit(X_train, y_train)
rf_pred = rf_model.predict(X_test)

print("üîπ Random Forest Evaluation:")
for i, target in enumerate(['PTS', 'TRB', 'AST']):
    mse = mean_squared_error(y_test.iloc[:, i], rf_pred[:, i])
    r2 = r2_score(y_test.iloc[:, i], rf_pred[:, i])
    print(f"{target} - RMSE: {mse**0.5:.2f}, R¬≤: {r2:.2f}")

for i, target in enumerate(['PTS', 'TRB', 'AST']):
    plt.figure(figsize=(6, 4))
    plt.scatter(y_test.iloc[:, i], rf_pred[:, i], alpha=0.6)
    plt.plot([y_test.iloc[:, i].min(), y_test.iloc[:, i].max()],
             [y_test.iloc[:, i].min(), y_test.iloc[:, i].max()], 'r--')
    plt.xlabel(f"Actual {target}")
    plt.ylabel(f"Predicted {target}")
    plt.title(f"[Random Forest] Actual vs Predicted - {target}")
    plt.show()

def predict_player_performance_avg(player_name, opponent_team):
    player_name = player_name.strip().title()
    opponent_team = opponent_team.strip().upper()

    player_data = df[(df['Player'] == player_name) & (df['Opp'] == opponent_team)]

    if player_data.empty:
        # Relax condition: search only by player name
        player_only = df[df['Player'] == player_name]
        if player_only.empty:
            print(f"‚ùå Player '{player_name}' not found in the dataset.")
        else:
            print(f"‚ö†Ô∏è No games found for '{player_name}' against '{opponent_team}'.")
            print("üìå But here are the teams this player has played against:")
            print(player_only['Opp'].unique())
        return

    avg_features = player_data[X.columns].mean().to_frame().T
    prediction = xgb_model.predict(avg_features)

    predicted_pts, predicted_trb, predicted_ast = prediction[0]
    print(f"üìä Predicted Stats (Avg vs {opponent_team}) for {player_name}:")
    print(f"  - Points: {predicted_pts:.2f}")
    print(f"  - Rebounds: {predicted_trb:.2f}")
    print(f"  - Assists: {predicted_ast:.2f}")

predict_player_performance_avg("Lebron james", "")